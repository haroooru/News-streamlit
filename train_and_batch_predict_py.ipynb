{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark requests streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5_1HyEMYIYA",
        "outputId": "f6bd25ab-6afc-4266-a276-97e6477adccc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.5.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_and_batch_predict.py\n",
        "\n",
        "- Trains a PySpark ML pipeline on sample (or your) labeled headlines.\n",
        "- Evaluates on test split (accuracy, precision, recall, f1).\n",
        "- Fetches a batch of headlines from NewsData (or any API) and predicts.\n",
        "- Saves the fitted PipelineModel for later streaming/inference.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF, StringIndexer, IndexToString\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "# ---- Configuration ----\n",
        "API_KEY = os.environ.get(\"NEWS_API_KEY\", \"pub_a09c97e2a49e401c985ff9c287794f90\")  # replace with your key or set env var\n",
        "NEWS_API_ENDPOINT = f\"https://newsdata.io/api/1/news?apikey={API_KEY}&language=en\"\n",
        "MODEL_SAVE_PATH = \"./saved_pipeline_model\"\n",
        "\n",
        "# ---- Spark session ----\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NewsSentimentTrain\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# -------- Example training data ----------\n",
        "# Ideally replace this small example with a real labeled dataset (CSV/Parquet)\n",
        "training_data = [\n",
        "    (\"Stocks rally after economic boost\", \"Positive\"),\n",
        "    (\"Disaster strikes coastal town\", \"Negative\"),\n",
        "    (\"Tech companies report record profits\", \"Positive\"),\n",
        "    (\"Market crashes amid fears\", \"Negative\"),\n",
        "    (\"Local team wins championship after extra time\", \"Positive\"),\n",
        "    (\"New evidence suggests policy failure\", \"Negative\"),\n",
        "    (\"Breakthrough in renewable energy announced\", \"Positive\"),\n",
        "    (\"Severe storms cause travel disruption\", \"Negative\"),\n",
        "    (\"Company reports higher-than-expected earnings\", \"Positive\"),\n",
        "    (\"Scandal leads to resignation of leader\", \"Negative\")\n",
        "]\n",
        "\n",
        "train_df = spark.createDataFrame(training_data, [\"headline\", \"label\"])\n",
        "train_df.show(truncate=False)\n",
        "\n",
        "# ---- Build pipeline ----\n",
        "tokenizer = Tokenizer(inputCol=\"headline\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\", handleInvalid=\"keep\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"labelIndex\", maxIter=20)\n",
        "\n",
        "# We do NOT include IndexToString in training pipeline because IndexToString needs fitted labels mapping.\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, label_indexer, lr])\n",
        "\n",
        "# ---- Train/test split ----\n",
        "train, test = train_df.randomSplit([0.8, 0.2], seed=42)\n",
        "fitted_pipeline = pipeline.fit(train)\n",
        "\n",
        "# ---- Evaluate ----\n",
        "pred_test = fitted_pipeline.transform(test)\n",
        "\n",
        "# Multi-class evaluator supports 'accuracy' and 'f1'. For precision/recall you can use the \"weightedPrecision\"/\"weightedRecall\"\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "\n",
        "acc = evaluator_acc.evaluate(pred_test)\n",
        "f1 = evaluator_f1.evaluate(pred_test)\n",
        "prec = evaluator_precision.evaluate(pred_test)\n",
        "rec = evaluator_recall.evaluate(pred_test)\n",
        "\n",
        "print(f\"Evaluation on test set -> Accuracy: {acc:.4f}, F1: {f1:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
        "\n",
        "# ---- Convert numeric prediction back to original labels properly ----\n",
        "# After fitting, find the label order from the fitted StringIndexer stage\n",
        "# In our pipeline, stage index 3 is label_indexer (0:tokenizer,1:hashingTF,2:idf,3:label_indexer,4:lr)\n",
        "fitted_label_indexer = fitted_pipeline.stages[3]\n",
        "labels = fitted_label_indexer.labels  # list like ['Positive','Negative'] in some order\n",
        "print(\"Label indexer labels (index -> label):\")\n",
        "for i, lbl in enumerate(labels):\n",
        "    print(f\"  {i} -> {lbl}\")\n",
        "\n",
        "index_to_string = IndexToString(inputCol=\"prediction\", outputCol=\"Predicted_Label\", labels=labels)\n",
        "\n",
        "# Apply converter to predictions and show\n",
        "predictions_with_labels = index_to_string.transform(pred_test)\n",
        "predictions_with_labels.select(\"headline\", \"label\", \"Predicted_Label\", \"probability\").show(truncate=False)\n",
        "\n",
        "# ---- Save the fitted pipeline model (so we can load and use in streaming / dashboard) ----\n",
        "# We will save the fitted pipeline WITHOUT IndexToString - we'll save it separately as a small convenience file.\n",
        "# Save the fitted pipeline (it contains the tokenizer, tf, idf, label_indexer and lr)\n",
        "fitted_pipeline.write().overwrite().save(MODEL_SAVE_PATH)\n",
        "print(\"Saved fitted pipeline to:\", MODEL_SAVE_PATH)\n",
        "\n",
        "# Save the labels mapping to a tiny file for IndexToString usage later\n",
        "# We'll write a plain text file with labels\n",
        "labels_path = os.path.join(MODEL_SAVE_PATH, \"labels.txt\")\n",
        "with open(labels_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(labels))\n",
        "print(\"Saved labels to:\", labels_path)\n",
        "\n",
        "# ---- Batch fetch headlines and predict (demo) ----\n",
        "def fetch_headlines(limit=10):\n",
        "    try:\n",
        "        resp = requests.get(NEWS_API_ENDPOINT, timeout=15)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        results = data.get(\"results\", []) if isinstance(data, dict) else []\n",
        "        titles = [r.get(\"title\") for r in results if r.get(\"title\")]\n",
        "        return titles[:limit]\n",
        "    except Exception as e:\n",
        "        print(\"Warning: fetch failed:\", e)\n",
        "        # return demo headlines on failure\n",
        "        return [\n",
        "            \"Stocks rally after economic boost\",\n",
        "            \"Unexpected market turbulence causes losses\",\n",
        "            \"Local startup secures major funding\"\n",
        "        ]\n",
        "\n",
        "batch_headlines = fetch_headlines(limit=20)\n",
        "print(\"Fetched headlines (batch):\", batch_headlines[:5])\n",
        "\n",
        "# Load saved pipeline and predict\n",
        "loaded_pipeline = PipelineModel.load(MODEL_SAVE_PATH)\n",
        "\n",
        "# Create spark DF and predict\n",
        "predict_df = spark.createDataFrame([(h,) for h in batch_headlines], [\"headline\"])\n",
        "preds = loaded_pipeline.transform(predict_df)\n",
        "\n",
        "# apply IndexToString with labels we saved\n",
        "# Read saved labels\n",
        "with open(labels_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    saved_labels = [l.strip() for l in f if l.strip()]\n",
        "\n",
        "index_to_string = IndexToString(inputCol=\"prediction\", outputCol=\"Predicted_Label\", labels=saved_labels)\n",
        "preds = index_to_string.transform(preds)\n",
        "preds.select(\"headline\", \"Predicted_Label\", \"probability\").show(truncate=False)\n",
        "\n",
        "# Done\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJapK1_bYI1W",
        "outputId": "606709d0-cd6f-4791-fcb3-7ada201aa4f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------+--------+\n",
            "|headline                                     |label   |\n",
            "+---------------------------------------------+--------+\n",
            "|Stocks rally after economic boost            |Positive|\n",
            "|Disaster strikes coastal town                |Negative|\n",
            "|Tech companies report record profits         |Positive|\n",
            "|Market crashes amid fears                    |Negative|\n",
            "|Local team wins championship after extra time|Positive|\n",
            "|New evidence suggests policy failure         |Negative|\n",
            "|Breakthrough in renewable energy announced   |Positive|\n",
            "|Severe storms cause travel disruption        |Negative|\n",
            "|Company reports higher-than-expected earnings|Positive|\n",
            "|Scandal leads to resignation of leader       |Negative|\n",
            "+---------------------------------------------+--------+\n",
            "\n",
            "Evaluation on test set -> Accuracy: 0.5000, F1: 0.3333, Precision: 0.2500, Recall: 0.5000\n",
            "Label indexer labels (index -> label):\n",
            "  0 -> Negative\n",
            "  1 -> Positive\n",
            "+------------------------------------------+--------+---------------+------------------------------------------------------------+\n",
            "|headline                                  |label   |Predicted_Label|probability                                                 |\n",
            "+------------------------------------------+--------+---------------+------------------------------------------------------------+\n",
            "|Market crashes amid fears                 |Negative|Negative       |[0.6115958457661239,0.386922889026743,0.0014812652071330649]|\n",
            "|Breakthrough in renewable energy announced|Positive|Negative       |[0.6115958457661239,0.386922889026743,0.0014812652071330649]|\n",
            "+------------------------------------------+--------+---------------+------------------------------------------------------------+\n",
            "\n",
            "Saved fitted pipeline to: ./saved_pipeline_model\n",
            "Saved labels to: ./saved_pipeline_model/labels.txt\n",
            "Fetched headlines (batch): [\"'Unless He Gets Himself Out': 1983 WC Hero Feels Pakistan Has No Answer To Abhishek Sharma In Asia Cup 2025 Final\", 'Adobe brings new AI-driven functionalities in Photoshop - UNITED NEWS OF INDIA', \"Cha Heung Seung diagnosed with cancer; ‘Single’s Inferno’ star shares resolve: 'I will overcome this and - The Times of India\", 'What James Franklin said after No. 3 Penn State lost to No. 6 Oregon in double overtime - OregonLive.com', 'Brisbane Broncos vs Penrith Panthers: NRL preliminary final live scores, blog']\n",
            "+-----------------------------------------------------------------------------------------------------------------------------+---------------+--------------------------------------------------------------+\n",
            "|headline                                                                                                                     |Predicted_Label|probability                                                   |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------+---------------+--------------------------------------------------------------+\n",
            "|'Unless He Gets Himself Out': 1983 WC Hero Feels Pakistan Has No Answer To Abhishek Sharma In Asia Cup 2025 Final            |Negative       |[0.9801194376326078,0.019373766749005327,5.067956183868942E-4]|\n",
            "|Adobe brings new AI-driven functionalities in Photoshop - UNITED NEWS OF INDIA                                               |Negative       |[0.999442383735638,4.77210961287596E-4,8.040530307447956E-5]  |\n",
            "|Cha Heung Seung diagnosed with cancer; ‘Single’s Inferno’ star shares resolve: 'I will overcome this and - The Times of India|Negative       |[0.9801194376326078,0.019373766749005327,5.067956183868942E-4]|\n",
            "|What James Franklin said after No. 3 Penn State lost to No. 6 Oregon in double overtime - OregonLive.com                     |Positive       |[0.4600430561190659,0.5378072860244846,0.0021496578564496006] |\n",
            "|Brisbane Broncos vs Penrith Panthers: NRL preliminary final live scores, blog                                                |Negative       |[0.6115958457661239,0.386922889026743,0.0014812652071330649]  |\n",
            "|Bhima River Floods Karnataka Villages, Crops And Homes Damaged                                                               |Negative       |[0.991146961760695,0.008617743725188184,2.3529451411670574E-4]|\n",
            "|Bank of America Issues Pessimistic Forecast for United Parcel Service (NYSE:UPS) Stock Price                                 |Negative       |[0.9801194376326078,0.019373766749005327,5.067956183868942E-4]|\n",
            "|Americas Silver (TSE:USA) PT Set at C$6.00 by Desjardins                                                                     |Negative       |[0.6115958457661239,0.386922889026743,0.0014812652071330649]  |\n",
            "|Trump-Netanyahu meeting: US ramping up pressure for end of war, Israel eyes West Bank annexation                             |Negative       |[0.9801194376326078,0.019373766749005327,5.067956183868942E-4]|\n",
            "|Fact Check: Has Tom Brady Been Fired by FOX?                                                                                 |Negative       |[0.6115958457661239,0.386922889026743,0.0014812652071330649]  |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------+---------------+--------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}